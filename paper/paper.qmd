---
title: "The Effects of Homeless Shelter Occupancy on Non-Fatal Opioid Overdoses"
subtitle: "My subtitle if needed"
author: 
  - Justin Klip
thanks: "Code and data are available at: [https://github.com/justinklip/toronto_shelter_overdose_study)."
date: today
date-format: long
abstract: "First sentence. Second sentence. Third sentence. Fourth sentence."
format: pdf
number-sections: true
bibliography: references.bib
---

```{r}

```

# Introduction

Overview Paragraph: Opioid overdoses have been a prominent issue in North America for some time. Opioid-related deaths have doubled in Canada from 2019 to the end of 2021 (https://www.cbc.ca/news/health/opioid-young-people-1.7174098). It has been well-documented that homeless people are a large subset of the population affected by this crisis, with more than 10% of opioid deaths in Toronto being attributed to individuals experiencing homelessness in 2023 (chrome-extension://efaidnbmnnnibpcajpcglclefindmkaj/https://www.toronto.ca/wp-content/uploads/2020/12/8d4b-TOIS-Coroner-Data_Final.pdf). Homeless opioid overdoses in shelters have climbed as well during the pandemic, with opioid deaths in Ontario shelters more than tripling during the pandemic (https://www.cbc.ca/news/canada/toronto/ont-shelters-overdose-deaths-1.7238916). There are a lot of factors that could play into this, but one question that is left to be asked is if the conditions in  the shelters themselves may be contributing to this.

Results paragraph

Why it matters paragraph

Telegraphing paragraph: The remainder of this paper is structured as follows. @sec-data describes how the data was acquired, how it was measured, and provides visualizations on the overdoses and occupancy in shelters.
# Data {#sec-data}

## Data Source

I make use of two data sources in order to run my analysis. Firstly I make use of Open Data Toronto's Daily Shelter Overnight Capacity Data (cite). Secondly I use Open Data Toronto's Fatal and Non-Fatal Suspected Opioid Overdoses in the Shelter System data set (cite). These data sets compile

Using the statistical programming language R [@citeR], the data was then cleaned, tested, and merged using (cite packages). The daily shelter attendance data was aggregated from the daily data in the shelter data base to a quarterly record in order to merge with the overdose data set. Details are in the appendix on how exactly observations were dropped and merged (cross-reference appendix). Some dummy variables were added into the data set in order to account for selection induced upon dropping missing values. Data such as

Overview text

## Measurement

The Daily Shelter Overnight Capacity Data from Open Data Toronto is measured directly from administrative data (cite). According to Open Data Toronto, this administrative data comes from the Toronto Shelter and Support Services division's Shelter Management Information (SMIS) database. The data is generated as follows: a shelter records metrics in their shelter at exactly 4:00am every day (likely through a computer or check-in system) such as attendance numbers, capacity numbers, and respective capacity utilization rates, then uploads that data daily in compliance with the SMIS data requirements. Generally shelters measured occupancy and capacity in one of two ways: beds or rooms. Bed-based occupancy was used in shelters that had communal sleeping areas, whereas room-based occupancy was used for more family-oriented programs. An "individual" in this data set would counts as someone who was served in a service area or program (https://www.toronto.ca/city-government/data-research-maps/research-reports/housing-and-homelessness-research-and-reports/shelter-census/). Interestingly data is only recorded for the first quarter of 2023, this and other limitations of the data are discussed further in the (@appendix)

The Fatal and Non-Fatal Suspected Opioid Overdoses in the Shelter System Data Set (cite) comes from paramedic rather than shelter level data. This data only counts for specific kinds of shelters: shelter-hotels, emergency shelters, and shelter-hotels, meaning that when the data is merged, only shelters coming from this data set will be used. An entry in the data set is formed as follows: a shelter member or employee calls 911 for an emergency, when Paramedics arrive and if they determine on the scene that this is a suspected overdose, then that location gets an observation added to the data set. It's important to note also that if a particular address has less than 5 non-fatal overdoses in a particular quarter, then the true amount is not published for anonymity purposes. This data set also includes fatal overdoses, and a fatal overdose is only added as an entry if the Coroner's office determines the cause of death to be an overdose. This data is also not matched at the shelter level and is only aggregate statistics, so it will be ignored for the purpose of analysis since I am more interested in the relationship between capacity and overdoses.

## Outcome variables

```{r}
#| fig-label: fig-1
#| fig-cap: Shelters Reporting Overdoses by Quarter-Year"
#| echo: false
#| warning: false

library(arrow)
library(tidyverse)
library(here)

# Set the path to your parquet file
file_path <- here("data", "02-analysis_data", "shelter_analysis_data.parquet")

# Read the Parquet file into a dataframe
shelter_analysis_data <- read_parquet(file_path)

# Create a new column for overdose categories ("<5" vs ">5")
shelter_analysis_data <- shelter_analysis_data %>%
  mutate(overdose_category = case_when(
    suspected_non_fatal_overdoses == "< 5" ~ "<5",
    suspected_non_fatal_overdoses != "< 5" & suspected_non_fatal_overdoses != "" ~ ">5",
    TRUE ~ NA_character_ # If empty or NA, we'll handle this later
  ))

# Create a new column for numeric overdoses (replace "<5" with NA for now)
shelter_analysis_data$non_fatal_overdoses_numeric <- 
  ifelse(shelter_analysis_data$suspected_non_fatal_overdoses == "< 5", NA, 
         as.numeric(shelter_analysis_data$suspected_non_fatal_overdoses))

# Remove duplicates: Keep only one row per shelter per quarter-year
shelter_analysis_data_unique <- shelter_analysis_data %>%
  distinct(year, year_stage, address, .keep_all = TRUE)  # Assuming 'shelter_id' identifies shelters

# Aggregate data by year, quarter, and overdose category
overdose_summary <- shelter_analysis_data_unique %>%
  group_by(year, year_stage, overdose_category) %>%
  summarise(count = n(), .groups = 'drop')  # Count number of shelters per category

# Convert year and quarter to a single "quarter-year" column for easier plotting
overdose_summary <- overdose_summary %>%
  mutate(quarter_year = paste(year, "", year_stage, sep = "-"))

# Plot the segmented bar chart
ggplot(overdose_summary, aes(x = quarter_year, y = count, fill = overdose_category)) +
  geom_bar(stat = "identity", position = "stack") +
  labs(
    x = "Quarter-Year",
    y = "Number of Shelters",
    fill = "Overdose Category"
  ) +
  theme_minimal() +
  scale_fill_manual(values = c("<5" = "lightblue", ">5" = "red")) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Rotate x-axis labels for readability

```

@fig-1 Provides information on the number of overdoses for each shelter in the data set from quarter to quarter. It is important to note that the data set does not include Q4 data. The first thing to note is that the number of shelters seems to decrease in 2023, this is likely consistent with COVID-19 specific shelters beginning to close. Another important thing to note is that the number of overdoses greater than 5 and the amount less than 5 are generally split evenly between the shelters. This suggests we have some "high overdose" level shelters, likely because they are bigger, and others which are smaller and less drug prone. This also means our model must address the high level of <5 counts.


```{r}
#| fig-label: fig-2
#| fig-cap: Distribution of Overdoses, Shelter-By-Quarter
#| fig-subcap: This figure plots the number of overdoses the shelters experience each quarter
#| echo: false
#| warning: false

# Set the path to your parquet file
file_path <- here("data", "02-analysis_data", "shelter_analysis_data.parquet")

# Read the Parquet file into a dataframe
shelter_analysis_data <- read_parquet(file_path)

# Filter for numeric overdoses (>5 observations) and exclude "<5" and "0"
filtered_data <- shelter_analysis_data %>%
  filter(
    suspected_non_fatal_overdoses != "< 5",                # Exclude "<5" overdoses
    suspected_non_fatal_overdoses != "0",                 # Exclude "0" overdoses
    !is.na(suspected_non_fatal_overdoses)                 # Exclude missing values
  ) %>%
  mutate(
    non_fatal_overdoses_numeric = as.numeric(suspected_non_fatal_overdoses) # Convert to numeric
  )

# Create a new column for quarter-year
filtered_data <- filtered_data %>%
  mutate(quarter_year = paste(year, "Q", year_stage, sep = "-"))

# Plot the histogram for all non-0 and non-<5 observations
ggplot(filtered_data, aes(x = non_fatal_overdoses_numeric)) +
  geom_histogram(binwidth = 5, fill = "steelblue", color = "black", alpha = 0.8) +
  labs(
    x = "Number of Overdoses",
    y = "Number of Shelter Quarters",
  ) +
  theme_minimal()

```
@fig-2 Plots the distribution of the number of overdoses for all shelters (by quarter) that have more than 5 overdoses in a given quarter. The distribution suggests that the mean (if the distribution is skewed normal) is relatively low each quarter for a given shelter. In particular most of the mass is centered around 5-10 overdoses, suggesting that the mean could potentially be somewhere in the less than 0-10 overdoses range. It potentially could be less than 5, but due to the censored data it is hard to tell.

## Predictor variables

```{r}
library(ggplot2)
library(dplyr)

# Filter out missing values for avg_occupancy_rate if necessary
shelter_analysis_data <- shelter_analysis_data %>%
  filter(!is.na(avg_occupancy_rate))

# Create the faceted plot
ggplot(shelter_analysis_data, aes(x = avg_occupancy_rate, fill = factor(used_avg_occupancy_rate_beds))) +
  geom_histogram(binwidth = 5, alpha = 0.7, color = "black") +
  facet_wrap(~used_avg_occupancy_rate_beds, 
             labeller = as_labeller(c("0" = "Used Rooms Level Occupancy", "1" = "Used Bed Level Occupancy"))) +
  labs(
    title = "Distribution of Average Occupancy Rate by Type of Shelter",
    x = "Average Occupancy Rate",
    y = "Count",
    fill = "Used Beds Data"
  ) +
  theme_minimal() +
  scale_fill_manual(values = c("0" = "skyblue", "1" = "orange")) +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    legend.position = "none"  # Hide legend since facet labels provide the same information
  )
```
Figure 3 Plots the distribution of the average occupancy rate by quarter-year, as seen in some quarters shelters do have less than 100 percent occupancy, although a lot spend their time at the 95-100 percent occupancy rate. That being said, for the bed data there are a lot more observations with less than 95 to 100 percent occupancy. This makes sense as it is a lot easier for a shelter to fill up all their rooms than it is to fill all their beds. 

# Model

The goal of our modelling strategy is twofold. Firstly,...

Here we briefly describe the Bayesian analysis model used to investigate... Background details and diagnostics are included in [Appendix -@sec-model-details].

## Model set-up

Define $y_i$ as the number of seconds that the plane remained aloft. Then $\beta_i$ is the wing width and $\gamma_i$ is the wing length, both measured in millimeters.

```{=tex}
\begin{align} 
y_i|\mu_i, \sigma &\sim \mbox{Normal}(\mu_i, \sigma) \\
\mu_i &= \alpha + \beta_i + \gamma_i\\
\alpha &\sim \mbox{Normal}(0, 2.5) \\
\beta &\sim \mbox{Normal}(0, 2.5) \\
\gamma &\sim \mbox{Normal}(0, 2.5) \\
\sigma &\sim \mbox{Exponential}(1)
\end{align}
```
We run the model in R [@citeR] using the `rstanarm` package of @rstanarm. We use the default priors from `rstanarm`.

### Model justification

We expect a positive relationship between the size of the wings and time spent aloft. In particular...

We can use maths by including latex between dollar signs, for instance $\theta$.

# Results

Our results are summarized in @tbl-modelresults.

# Discussion

## First discussion point {#sec-first-point}

If my paper were 10 pages, then should be be at least 2.5 pages. The discussion is a chance to show off what you know and what you learnt from all this.

## Second discussion point

Please don't use these as sub-heading labels - change them to be what your point actually is.

## Third discussion point

## Weaknesses and next steps

Weaknesses and next steps should also be included.

\newpage

\appendix

# Appendix {.unnumbered}

# Additional data details

# Model details {#sec-model-details}

## Posterior predictive check

## Diagnostics

\newpage

# References
